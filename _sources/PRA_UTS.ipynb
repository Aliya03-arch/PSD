{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ab796f2",
   "metadata": {},
   "source": [
    "# PRA UTS PSD_B_Aliya Zulfa Syafitri_23-157"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d7b3c8",
   "metadata": {},
   "source": [
    "### Langkah - langkah Pengerjaan\n",
    "\n",
    "### 1. Mengunduh alat - alat yang dibutuhakan\n",
    "Knime dan PostgreSQL JDBC Driver.\n",
    "\n",
    "### 2. Membuat data baru di Knime\n",
    "Tekan tombol \"create new workflow\", setelah itu akan muncul tombol untuk membuat datanya.\n",
    "\n",
    "### 3. Pilih Nodes yang dibutuhkan\n",
    "Setelah itu tarik nodes apa saja yang akan digunakan, disini saya menggunakan beberapa nodes seperti di gambar.\n",
    "\n",
    "![image10.png](image10.png)\n",
    "\n",
    "### 5. Mengkofigurasi Nodes yang diperlukan\n",
    "Untuk menghubungkan database postgesql ke Knime.\n",
    "\n",
    "![image11.png](image11.png)\n",
    "\n",
    "Untuk memilih data yang akan digunakan.\n",
    "\n",
    "![image12.png](image12.png)\n",
    "\n",
    "Setelah ini dilakakun, selanjutnya menjalankan apakah database berhasil terhubung ke Knime.\n",
    "\n",
    "### 6. Mengisi Script Python\n",
    "isi Script Python di dalam Python Script (Legacy), jika Python Script (Legacy) tidak ada di nodes yang perlu kalian lalukan adalah membuat environment terlebih dahulu di miniconda atau di anaconda saya menggunakan anaconda untuk membuat environment saya.\n",
    "\n",
    "\n",
    "Ini adalah Script Python yang saya gunakan:\n",
    "- IMPORT LIBRARY \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "- AMBIL DATASET DARI KNIME\n",
    "dataset = input_table_1.copy()\n",
    "\n",
    "print(\"=== INFO DATASET ===\")\n",
    "print(dataset.head())\n",
    "print(\"\\nKolom terdeteksi:\", list(dataset.columns))\n",
    "\n",
    "- DETEKSI KOLOM TARGET SECARA OTOMATIS\n",
    "if 'localization' in dataset.columns:\n",
    "    target_col = 'localization'\n",
    "else:\n",
    "    target_col = dataset.columns[-1]\n",
    "print(f\"Kolom target digunakan: {target_col}\")\n",
    "\n",
    "- KONVERSI SEMUA FITUR KE NUMERIK (KECUALI TARGET) \n",
    "X_raw = dataset.drop(columns=[target_col], errors='ignore')\n",
    "y = dataset[target_col]\n",
    "\n",
    "- Paksa ubah ke numerik, selain target\n",
    "X = X_raw.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "- Hapus kolom yang semuanya NaN (misalnya kolom teks seperti 'protein_name')\n",
    "X = X.dropna(axis=1, how='all')\n",
    "\n",
    "- Jika semua kolom hilang, hentikan\n",
    "if X.shape[1] == 0:\n",
    "    raise ValueError(\"Tidak ada kolom numerik yang valid setelah konversi. Periksa dataset Anda.\")\n",
    "\n",
    "- IMPUTASI MISSING VALUE\n",
    "missing_info = X.isna().sum()\n",
    "print(\"\\nJumlah missing value awal:\\n\", missing_info)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "- DETEKSI OUTLIER (Z-SCORE) \n",
    "z_scores = np.abs((X - X.mean()) / X.std())\n",
    "outlier_mask = (z_scores > 3)\n",
    "\n",
    "- Jumlah baris yang mengandung minimal satu outlier\n",
    "num_outlier_rows = outlier_mask.any(axis=1).sum()\n",
    "persen_outlier = (num_outlier_rows / len(X)) * 100\n",
    "\n",
    "print(f\"\\nJumlah baris dengan outlier: {num_outlier_rows}\")\n",
    "print(f\"Persentase data outlier: {persen_outlier:.2f}%\")\n",
    "\n",
    "- Tambahkan kolom indikator outlier\n",
    "X['is_outlier'] = outlier_mask.any(axis=1).astype(int)\n",
    "\n",
    "- CEK KETIDAKSEIMBANGAN DATA \n",
    "class_dist = Counter(y)\n",
    "print(\"\\nDistribusi kelas:\", class_dist)\n",
    "\n",
    "- STANDARISASI DATA \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "- SPLIT DATA \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "- TRAIN MODEL \n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "- EVALUASI MODEL \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"\\n=== LAPORAN KLASIFIKASI ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\"\\nAkurasi Model: {acc*100:.2f}%\")\n",
    "\n",
    "- OUTPUT UNTUK KNIME\n",
    "output_table_1 = pd.DataFrame({'Prediksi': y_pred})\n",
    "output_table_2 = pd.DataFrame({\n",
    "    'Kolom': missing_info.index,\n",
    "    'Jumlah Missing': missing_info.values\n",
    "})\n",
    "output_table_3 = pd.DataFrame({\n",
    "    'Kelas': list(class_dist.keys()),\n",
    "    'Jumlah Data': list(class_dist.values())\n",
    "})\n",
    "output_table_4 = pd.DataFrame({\n",
    "    'Jumlah Outlier (baris)': [num_outlier_rows],\n",
    "    'Persentase Outlier (%)': [round(persen_outlier, 2)],\n",
    "    'Akurasi Model (%)': [round(acc * 100, 2)]\n",
    "})\n",
    "\n",
    "print(\"\\nContoh hasil prediksi:\")\n",
    "print(output_table_1.head())\n",
    "\n",
    "Setelah berhasil dijalankan, akan muncul hasilnya\n",
    "### Hasil\n",
    "\n",
    "![image13.png](image13.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
